{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rzl-ds/gu511/blob/master/005_python.ipynb\" target=\"_parent\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## why might you use `python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[`python`](https://www.python.org/) is one of the most popular scripting and programming languages in the world. there are, [like, ninefinity different ways of ranking programming lanaguages](https://en.wikipedia.org/wiki/Measuring_programming_language_popularity#Indices), and `python` sits in the top 5 of almost every one of them.\n",
    "\n",
    "I have used it on every single project I've ever worked on. I am an unashamed `python` fanboy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "though I like to poke fun at `R`, I'm not really one for the `R` vs. `python` holy wars -- the two have different use cases and any conversation that attempts to settle \"which is better\" is already fundamentally flawed, in my opinion. That being said, I'd like to make the following case as to why you should *learn* `python`, even if it doesn't become your go-to data science language:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### `python` is much more common than `R` *outside* the statistics community\n",
    "\n",
    "this is a feature of a number of biases, but also speaks to something fundamental about the differences between the languages: `R` is a very *deep* language in a very *narrow* field of concepts (namely, statistics), whereas `python` is among the most *broad* and *flexible* languages without a central purpose.\n",
    "\n",
    "Another reason this matters: the barrier to entry for a company or government agency's IT department will be lower (or already surpassed) for `python` and `python` packages if for no other reason than that computer engineers are either already familiar with it or much more comfortable expanding into it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### the deep learning field is very much entrenched on the `python` side of the fence\n",
    "\n",
    "though there are ways to communicate out of `R` and into `python` sessions for access to the deep learning frameworks, the action is all in `python`.\n",
    "\n",
    "if you are looking to do deep learning, the easiest path forward will be in `python` rather than `R`.\n",
    "\n",
    "*note: you could correctly argue that the action is actually **really** all in `C` and `C++` but the action `api`s are in `python`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### there is a package for that\n",
    "\n",
    "this is a corollary of the previous point: if there is a thing you want to do, it is very likely that some one has already done it in `python`, and that their work is available for you to use.\n",
    "\n",
    "For a point of comparison, there are [14,949 `R` packages on `CRAN`](https://cran.r-project.org/web/packages/), and [197,199 on `pypi`](https://pypi.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import antigravity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### it does all the most basic things well\n",
    "\n",
    "although it is available and well-supported on every OS, `python` is very much a linux-focused language. it \"grew up\" in linux as an alternative scripting language (alternative to `bash` and other `shell` scripts). because of this, it acquired some of the linux philosophy points, and specifically those that focus on simplicity.\n",
    "\n",
    "many of the current iterations of linux tools are actually calling `python` scripts under the hood, which means that essential things like web scraping, emailing, scheduling and timing, networking, logging, and database access are all possible and highly optimized in `python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### it is fun\n",
    "\n",
    "`python` was created with the express interest of being as simple to program in as possible. most of the syntax and rules are specifically generated to make the language function as much like pseudo-code as possible, so code is easy to read.\n",
    "\n",
    "the community also has an edge to it. a good example: start a python session and type\n",
    "\n",
    "```python\n",
    "import this\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "okay, so it's a particular type of fun for a particular type of person. but given the prior that you're in this class, I suppose that's a safer prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## why might you not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### version 2 vs. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "I'd be remiss not to mention one of the major red marks against `python` -- the infamous \"2 vs. 3\" upgrade controversy.\n",
    "\n",
    "in order to make some very low-level changes to the language (primarily for performance improvements and to support international languages), the developer community chose to make a new major version of `python`: `python3`.\n",
    "\n",
    "the process caused a lot of confusion among newcomers to the language -- which was exploding in popularity at around the same time -- and also put a large burden of uncertainty on corporate developers and development.\n",
    "\n",
    "the bottom line, in my opinion is this:\n",
    "\n",
    "***unless you have no other option, you should always use python 3 and only python 3***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### it's not *built* for statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "every single decision made in the development of the `R` programming language has been optimized for a particular audience (statisticians) with a particular task (statistics). as such, it does some things that computer scientists and software developers find baffling but are extremely intuitive to data scientists.\n",
    "\n",
    "the river often flows in the other direction in `python` world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<div align=\"center\">open floor: if you like `python`, why? if you don't, why not?</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "a given file of executible `python` code is probably best referred to as a \"script\", but a collection of scripts which expose some sort of interface to a user to do \"something\" are generally called a \"package\" (or sometimes a \"library\", especially for the built-in packages).\n",
    "\n",
    "This is mostly the same convention as in the `R` community -- think of the differences between scripts you wrote and `dplyr` and all the other stuff Hadley wrote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## my favorite packages\n",
    "\n",
    "So what sorts of `python` packages should you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "first of all, the builtin packages are pretty great, and cover a wide range of the most necessary use cases for a programming language (e.g. file i/o and os utilities and tie-ins). The ones I use most often are:\n",
    "\n",
    "+ `argparse` - reading in and parsing command line arguments\n",
    "+ `collections` - sets of \"collection\" objects (e.g. ordered dictionaries, named tuples, default dictionaries)\n",
    "+ `csv` - for reading and writing delimited files\n",
    "+ `datetime` - the fundamental date object and utilities package\n",
    "+ `functools` - functional tools, including fancy stuff like partial function definitions and caching\n",
    "+ `itertools` - an awesome package of utilities for iterating through collections of items\n",
    "+ `json` - for parsing and constructing well formatted JSON\n",
    "+ `logging` - for logging messages to console, file, etc\n",
    "+ `os` - operating system interaction (I use this in almost every single program)\n",
    "+ `pickle` - a `python`-native serialization protocol, for saving `python` stuff\n",
    "+ `random` - a decent (if not special) randomization package\n",
    "+ `re` - regular expression parsing package\n",
    "+ `time` - a generic OS-level time interface\n",
    "\n",
    "for any `python` installation, these *already exist* -- no installation necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "there are also a ton of great open-source libraries for just about any purpose you might imagine. Again, the ones I use most often:\n",
    "\n",
    "+ `flask` - a `python` web framework (for standing up webpages)\n",
    "+ `ipython` - the best interactive shell, it just makes the normal python program look silly\n",
    "+ `jupyter` - the interactive extension of the above (`ipython`, this is what is used to make this bodacious document you see before you)\n",
    "+ `lxml` - a fast and flexible XML / HTML package\n",
    "+ `matplotlib` - a plotting package that is super useful but will make `R` users dream of their former glory\n",
    "+ `numpy` - NUMerical PYthon, a lot of super duper array and linear algebra glue code to make C and FORTRAN routines available in `python`.\n",
    "+ `pandas` - PANel DAta, a dataframe interface for feature data. This is the main data science package in `python` and, again, I use it in almost every single program\n",
    "+ `plotly` - an amazing plotting package\n",
    "+ `psycopg2` - a `postgres` package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ `requests` - the main web GET and POST package\n",
    "+ `scipy` - SCIentific PYthon, and extension of `numpy` to include a more scientific utilities\n",
    "+ `scrapy` - a flexibile but easy web scraping framework\n",
    "+ `seaborn` - something you import whenever you use `matplotlib` to make your plots non-heinous (also has some useful functions that no one has discovered yet)\n",
    "+ `selenium` - a javascript engine package (for when `requests` isn't good enough)\n",
    "+ `sklearn` - the other half of the primary data science workflow, an all-purpose modeling package\n",
    "+ `spacy`, sometimes `nltk` - NLP libraries\n",
    "+ `sqlalchemy` - an ORM package for most sql databases. It's pretty flashy and when you finally need it, you'll know in your heart.\n",
    "+ `tensorflow`, `torch`, and `keras` - the three big libraries for deep learning implementations\n",
    "+ `tqdm` - a fancy-pants progress bar package. You don't need it, but you want it.\n",
    "+ `yaml` - a package for parsing the world's greatest configuration format, Yet Another Markup Language (YAML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## installing packages\n",
    "\n",
    "So, let's take a journey together.\n",
    "\n",
    "Unlike `R`, the folks who put `python` together thought that people should care about the versions of the packages they installed. They didn't really do anything to make this happen in a sane way, though, so there were like ten different ways to install packages. \n",
    "\n",
    "If you learned `python` in the early days, you probably heard it was hard to install packages. Well, it was. Maybe it still is, depending on your attitude. That's right, I'm blaming the victim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Really, though, I'm sorry. If you're coming to `python` from `R` this probably feels silly. Why not just have an `install` function and install whatever you want? \n",
    "\n",
    "Why? Basically, because that's a bad idea for writing production-level software.\n",
    "\n",
    "production-level software is meant to be deterministic, and to be stable. Software that has the ability to install packages within the language has several disadvantages:\n",
    "\n",
    "1. avoids administrator oversight\n",
    "    1. having to ask your admin to install something is a *good* thing\n",
    "2. could install something malicious or broken without anyone knowing\n",
    "3. could install different versions on different machines at different times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Basically, the versions of all your packages matter, so you should care about that stuff. The `python` community is pretty stickly about that and has gone to great lengths (and, like, 15 different methods) to try and solve that problem. And today, that means that everyone is doing one of the following (and then some):\n",
    "\n",
    "+ using `pip` (\"Pip Installs Python\", and yes, recursive acronyms are annoying)\n",
    "+ using `pip`, but in a virtual environment\n",
    "    + often done using `virtualenv` or `pyenv`\n",
    "+ using `conda` (virtual environments on steroids or amphetamines, depending on whether you're a data scientist or sysad (resp))\n",
    "\n",
    "I advocate using `conda` for many reasons -- more on this in the next lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# actually writing and executing `python` code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## interactive shells: `ipython` and `jupyter notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the default `python` command opens a vanilla `python` shell, where you can execute any of the `python` commands your heart disires. that being said, the experience is obviously lacking the bells and whistles of any modern code development or execution environment.\n",
    "\n",
    "for your personal use, `IPython` (interactive `python` shell) and `jupyter notebook`s are as close as it comes to a *must install* package as there is.\n",
    "\n",
    "I personally think of `ipython` as being the primary means of developing software, and `jupyter` as being almost exclusively for exploratory documents and presentations, but you should do whatever works for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the documents and slideshows we've been using as lecture notes this whole time were created with `jupyter`, and I believe you used them extensively in 510. if it is still new to you, though, `jupyter` is a cool `python` package which allows you to execute interpreted `python` commands in a \"notebook\" format, where commands and notes are isolated into separate \"cells\" that can be executed on demand.\n",
    "\n",
    "there are a couple of popular \"ways\" of developing `python` code, and `jupyter` notebooks are probably the most popular.\n",
    "\n",
    "I highly recommend becomming familiar with both, but particularly `jupyter`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### what `jupyter` actually is\n",
    "\n",
    "based on my understanding of `jupyter` usage in 510, I am assuming most of you are familiar with how to *use* `jupyter notebook`s. I think it can still be helpful to know what `jupyter` actually *is*, and what it is *doing*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`jupyter` is a `python` package (we can install it!) that does a lot of different things, but the main thing it does is create a **service** (a long-running process that *listens* for requests and *responds* to them with information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ps -aef | grep jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "that long running service knows how to read specially-formatted `json` files (`.ipynb`). these files contain code snippets that `jupyter` (hopefully) knows how to run and text blocks it can render. take this file, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n100 /Users/zach.lamberty/personal/code/gu511/005_python.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "finally, this process knows how to start up different processes for handling calculations in different languages (kernels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "when a **client** (your web browser) access the `jupyter notebook` **service** (via `http`), you begin a back-and-forth communication that eventually leads to you executing `python` code here in this pretty browser window.\n",
    "\n",
    "note: this client-server paradigm comes up a lot, right? because we're communicating over `http`, we should be able to run `jupyter notebook` services anywhere in the world, and connect to them from anywhere else, as long as that `http` message can travel. hm... I smell a homework exercise... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "I bring up all of the above just to say: `jupyter` is complicated! you're doing a lot with not a lot of effort. good for you. as you go on and experience problems or quirks, most of them come back to this architecture. you have a central process running as someone (maybe not you), and your attempts to run `python` code are going through this filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### code in other languages with `jupyter`\n",
    "\n",
    "you may have noticed a cell I ran up above:\n",
    "\n",
    "```python\n",
    "%%bash\n",
    "head -n100 /Users/zach.lamberty/personal/code/gu511/005_python.ipynb\n",
    "```\n",
    "\n",
    "that `%%bash` piece is `ipython` / `jupyter` specific -- it won't work in regular `python`. in this case it enables me to write code in a different language (here, `bash`), and the `jupyter` service knows how to execute. `jupyter` currently [supports many programming languages this way](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels) (requires some installation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## editors and `IDE`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "an **editor** is any program which allows you to edit text. these can be extremely basic (notepad) on up through extremely full featured.\n",
    "\n",
    "an **`IDE`** (`i`ntegrated `d`evelopment `e`nvironment) is the combination of an editor with tools for developing, testing, and packagin software. these are often extensible via plugins and have special commands that allow you to take common actions (e.g. refactor code to rename a variable everywhere it occurs, or auto-complete function names or common design patterns as you type) very quickly.\n",
    "\n",
    "the fundamental concept of an IDE is usually a **project** (a collection of files and metadata about how they are related) rather than a single file. you develop projects rather than edit files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "as an analogy: `IDE`s are to software development what microsoft office is to writing letters. they are software that provide you with a huge range of tools to do many different things. you don't need all the tools, but it's nice to have all the ones you do need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "there are a multitude of options for developing code in `python`, and the choice really comes down to your personal preferrences.\n",
    "\n",
    "if you're looking for the simplest possible starting point for doing *exploration* (not development!), you should use `jupyter notebook`s. this is the best exploratory environment for data science that `python` has to offer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "if you've \"grown up\" coding in `RStudio`, you probably expect a windowed environment where you can write scripts, execute blocks, visualize output, and explore objects, you might want to consider:\n",
    "\n",
    "+ [`pycharm`](https://www.jetbrains.com/pycharm/)\n",
    "+ [`rodeo`](https://www.yhat.com/products/rodeo)\n",
    "+ [`spyder`](https://pythonhosted.org/spyder/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "additionally, recent updates to `RStudio` itself (using the `R` `reticulate` package) [allow you to run `python` code in `RStudio`](https://blog.rstudio.com/2018/10/09/rstudio-1-2-preview-reticulated-python/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "if you are looking for something that is a significant step up from your base text editor, but not yet all the bells and whistles of a project-based IDE, you should look into\n",
    "\n",
    "+ [`sublimetext`](https://www.sublimetext.com/)\n",
    "+ [`notepad++`](https://notepad-plus-plus.org)\n",
    "+ [`emacs`](https://www.gnu.org/software/emacs/download.html)\n",
    "+ [`vim`](https://www.vim.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "finally, if you're looking to really jump into development, I suggest (in order of my own personal preference)\n",
    "\n",
    "+ [`pycharm`](https://www.jetbrains.com/pycharm/)\n",
    "+ [`vscode`](https://code.visualstudio.com/)\n",
    "+ [`atom`](https://atom.io/)\n",
    "\n",
    "personally, I'm a huge fan of `pycharm` for my work, but `vscode` is a close second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "I also advocate for the cycle of\n",
    "\n",
    "1. do exploration in notebooks\n",
    "1. convert cells or blocks of related cells into parameterized functions\n",
    "1. collect related functions into packages\n",
    "1. write external packages and import directly into notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# a crash course of stuff you should know or learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "I know that Prof. Price covered `python` in his course, so this may be overkill. If you're a `python` pro, bear with me -- sit back and bask in your total l33tness while we take a lightning tour of things that I think are #important.\n",
    "\n",
    "some of these topics may feel a little out of left field, but they are things I've learned that I think are essential (but not sufficient) to being a good `python` programmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## code structure and organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ [pep8](https://www.python.org/dev/peps/pep-0008/) was a really good idea. you should follow it\n",
    "    + specifically pay attention to naming conventions. they are important!\n",
    "        + files: `someshortword.py`\n",
    "        + variables and function names: `lowercase_with_underscores` (aka `snake_case`)\n",
    "        + class names: `CamelCase`\n",
    "        + global constants: `ALL_CAPS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ there are basically two types of `py` file:\n",
    "    + modules: a file `thing.py` written so that I can run `import thing` in a `python` session and nothing happens, but now I have new `python` toys like `thing.foo` and `thing.bar`\n",
    "    + scripts: I can run `python thing.py` from a bash shell and it *does a thing*\n",
    "    + if your file does a combination of those two, you should ask yourself why (and probably not do that)\n",
    "+ if I run `import thing` and *something happens*, that is almost always not a good idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "for `python` files (not `jupyter notebooks`), this is\n",
    "\n",
    "a bad idea:\n",
    "\n",
    "```python\n",
    "# thing.py\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn.neural_network\n",
    "\n",
    "x = pd.read_csv('magicdata.csv')\n",
    "y = pd.read_csv('easytarget.csv')\n",
    "m = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(1E999, 1E99999999999999),\n",
    "    random_state=1337)\n",
    "\n",
    "m.fit(x, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "a better idea:\n",
    "\n",
    "```python\n",
    "# thing.py\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn.neural_network\n",
    "\n",
    "\n",
    "def load_xy(xfile='magicdata.csv', yfile='easytarget.csv'):\n",
    "    x = pd.read_csv(xfile)\n",
    "    y = pd.read_csv(yfile)  \n",
    "    return x, y\n",
    "   \n",
    "   \n",
    "def model(x, y):\n",
    "    m = sklearn.neural_network.MLPClassifier(\n",
    "        hidden_layer_sizes=(1E999, 1E99999999999999), \n",
    "        random_state=1337)\n",
    "    m.fit(x, y)\n",
    "    return m\n",
    "    \n",
    "\n",
    "def main(xfile='magicdata.csv', yfile='easytarget.csv'):\n",
    "    x, y = load_xy(xfile, yfile)\n",
    "    m = model(x, y)\n",
    "    print(m.coefs_)\n",
    "    \n",
    "\n",
    "# more on this later...\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<div align=\"center\">what are your questions so far??</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## defining functions\n",
    "\n",
    "the typical function definition in `python` has a standard structure\n",
    "\n",
    "```python\n",
    "def foo(a, b, c, d):\n",
    "    # stuff ...\n",
    "    return result\n",
    "```\n",
    "\n",
    "I want to cover two special topics related to how you define functions -- one thing you should do more of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `*args` and `**kwargs`\n",
    "\n",
    "before we dive into what `*args` and `**kwargs` are, let's quickly set terminology: in `python`, users can pass arguments to functions in two ways:\n",
    "\n",
    "1. as positional arguments (first, second, third argument)\n",
    "1. as keyword arguments (`x=...`, `date=...`, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "for example, the function\n",
    "\n",
    "```python\n",
    "foo(a, b, c, d)\n",
    "```\n",
    "\n",
    "can have its arguments passed in order (`a` is the first element passed in, `b` is the second, etc) or by assignment (`a=...`, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "# with only positional arguments\n",
    "foo(1, 2, 3, 4)\n",
    "\n",
    "# with only keyword arguments\n",
    "foo(a=1, b=2, c=3, d=4)\n",
    "\n",
    "# with a mix, but with ALL keywords AFTER ALL position\n",
    "foo(1, 2, c=3, d=4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "what is more, keyword arguments could be provided completely out of order\n",
    "\n",
    "```\n",
    "foo(1, d=4, c=3, b=2)\n",
    "```\n",
    "\n",
    "will assign `a=1` (positional) and then all the other variables as provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "under the hood, the management of variables provided to function in `python` in done a standard way: through the use of \"packing\" and \"unpacking\" of positional and keyword arguments.\n",
    "\n",
    "when reading the variables you provide for the function, `python` starts off by collecting any **positional** arguments you provide into a `tuple` we call `args` by convention. `python` requires that all positional arguments come first (otherwise, how would we know which variable name to assignt hat value to?)\n",
    "\n",
    "then, it collects any **keyword** arguments you provide into a `dict` we call `kwargs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "so when we invoke the function `foo(a, b, c, d)` we defined above as\n",
    "\n",
    "```python\n",
    "foo(1, 2, c=3, d=4)\n",
    "```\n",
    "\n",
    "this is seen as having `args = (1, 2)` and `kwargs = {'c': 3, 'd': 4}`\n",
    "\n",
    "if we had invoked it\n",
    "\n",
    "```python\n",
    "foo(1, d=4, c=3, b=2)\n",
    "```\n",
    "\n",
    "this is seen as having `args = (1, )` and `kwargs = {'b': 2, 'c': 3, 'd': 4}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "similarly,\n",
    "\n",
    "```python\n",
    "foo(1, 2, 3, 4)\n",
    "```\n",
    "\n",
    "would `args = (1, 2, 3, 4)` and `kwargs = {}`, and\n",
    "\n",
    "```python\n",
    "foo(a=1, b=2, c=3, d=4)\n",
    "```\n",
    "\n",
    "would `args = (, )` and `kwargs = {'a': 1, 'b': 2, 'c': 3, 'd': 4}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "knowing that this happens actually opens up major opportunity: you might already know that `python` supports variable length argument lists for any function -- that is, if you want a function where\n",
    "\n",
    "```python\n",
    "foo(1)\n",
    "foo(1, 2)\n",
    "foo(1, 2, 3)\n",
    "foo(1, 2, 3, 4)\n",
    "```\n",
    "\n",
    "are all defined and do basically the same thing, you can do that in `python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "there is a pretty essential builtin function that works in exactly this way, in fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "max(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "max(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "max(1, 2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "there are also arguments that allow you to provide a variable number of \"keyword\" arguments (arguments you pass in like `foo=bar, baz=buzz`). again, in base `python`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(a=1, b=2, c=3, x=-3, y=-2, z=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "both of these proceses work by leveraging the fact that `args` and `kwargs` are `tuple` and `dict`s (respectively) and can be arbitrary size. to allow for aribtrary number of positional or keyword arguments, we simply change the way we declare the function from\n",
    "\n",
    "```python\n",
    "def foo(a, b, c, d):\n",
    "    ...\n",
    "```\n",
    "\n",
    "to\n",
    "\n",
    "```python\n",
    "def foo(*args, **kwargs):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "you can read\n",
    "\n",
    "```python\n",
    "def foo(*args, **kwargs):\n",
    "    ...\n",
    "```\n",
    "\n",
    "as \"take all the positional arguments and pack them into a tuple named `args`; then put all keywords into a dictionary name `kwargs`\".\n",
    "\n",
    "in the body of the function `foo`, you could refer to `args` or `kwargs` and get *whatever* the user passed in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the `*` and the `**` here are doing the \"packing\" or the \"unpacking\"\n",
    "\n",
    "+ packing: collect positional or keyword arguments into tuples and dicts (resp)\n",
    "    + take a series of elements `x, 1, y, d, ...` and *pack* them into a tuple\n",
    "    + take a series of keyword-value statements `var1=val1, var2=val2, ...` and *pack* them into a dictionary\n",
    "+ unpacking: given a tuple or a dictionary, \"explode\" the elements into a list of positional or keyword arguments\n",
    "    + take a tuple `(x, 1, y, d, ...)` and convert it into a series of elements `x, 1, y, d, ...` inside a function call\n",
    "    + take a dictionary `{var1: val1, var2: val2, ...}` and convert it into a series of keyword=value statments `var1=val1, var2=val2, ...` inside a function call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "let's create a function to see what this looks like on both sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(*args, **kwargs):\n",
    "    print('args = {}'.format(args))\n",
    "    print('kwargs = {}'.format(kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only positional args\n",
    "foo(1, 2, 'a', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# only keyword args\n",
    "foo(val1=1, val2=2, val3='a', other_val='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a mix of both positional args and keyword args\n",
    "foo(1, 2, 'a', 'b', val1=3, val2=4, val3='c', val4='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "importantly, we can use the `*` and `**` operators to \"explode\" things we want to pass to a function. for example, the following function expects to receive *exactly* four arguments with names `a, b, c, d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar(a, b, c, d):\n",
    "    print('a = {}'.format(a))\n",
    "    print('b = {}'.format(b))\n",
    "    print('c = {}'.format(c))\n",
    "    print('d = {}'.format(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ if we provide 0 positional (non-named) argument, we must provide `a=`, `b=`, `c=`, and `d=` values in any order\n",
    "+ if we provide 1 positional (non-named) argument, it will be assigned to `a`, and we must provide `b=`, `c=`, and `d=` values in any order\n",
    "+ if we provide 2 positional (non-named) argument, they will be assigned to `a` and `b` (resp), and we must provide `c=`, and `d=` values in any order\n",
    "+ if we provide 3 positional (non-named) argument, it will be assigned to `a`, and we must provide `b=`, `c=`, and `d=` values in any order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "watch how we define a tuple of arguments `args` and explode it via `*args`, and how we do the same with a dictionary called `kwargs` we explode via `**kwargs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "args = tuple()\n",
    "kwargs = {'a': 'kw_arg_a',\n",
    "          'b': 'kw_arg_b',\n",
    "          'c': 'kw_arg_c',\n",
    "          'd': 'kw_arg_d'}\n",
    "bar(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "args = ('pos_arg_a', )\n",
    "kwargs = {'b': 'kw_arg_b',\n",
    "          'c': 'kw_arg_c',\n",
    "          'd': 'kw_arg_d'}\n",
    "bar(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "args = ('pos_arg_a', 'pos_arg_b', )\n",
    "kwargs = {'c': 'kw_arg_c',\n",
    "          'd': 'kw_arg_d', }\n",
    "\n",
    "bar(*args, **kwargs)\n",
    "# equivalent:\n",
    "bar(args[0], args[1], c=kwargs['c'], d=kwargs['d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "args = ('pos_arg_a', 'pos_arg_b', 'pos_arg_c' )\n",
    "kwargs = {'d': 'kw_arg_d'}\n",
    "bar(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "args = ('pos_arg_a', 'pos_arg_b', 'pos_arg_c', 'pos_arg_d', )\n",
    "kwargs = {}\n",
    "bar(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### real world use of `*args` or `**kwargs`\n",
    "\n",
    "there are a few common scenarios in which you might use `*args` or `**kwargs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ you are defining a function that takes an arbitrary number of parameters\n",
    "\n",
    "it's not to say that this is a *common* thing to do, but *if* you find yourself needing to do it, `*args` and `**kwargs` are the only way to do that thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ in class inheritance\n",
    "\n",
    "`python` allows you to define new `class`es that are \"child\" class of others via object inheritance. for example, in the [`keras`](https://keras.io/) deep learning `api`, users can create their own types of layers in a neural net architecture by [using class inheritance](https://keras.io/layers/writing-your-own-keras-layers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "class MyLayer(Layer):\n",
    "  def __init__(self, output_dim, **kwargs):  # kwargs allows arbitrary keyword arguments\n",
    "    self.output_dim = output_dim             # uses one (required) arg\n",
    "    super().__init__(**kwargs)               # passes all other args \"up\" the inheritance chain\n",
    "```\n",
    "\n",
    "it is common for `__init__` methods in classes to pass arguments \"up\" the inheritance chain by calling `super()` (get the parent class) and then calling `.__init__(*args, **kwargs)` on the parent. I can now pass any arguments to `MyLayer` that would work in `Layer` itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ if you are writing some sort of utility function where you are continually doing *slightly different* calls in the middle of doing exactly the same thing\n",
    "    + this is often called \"wrapping\" or \"decorating\" a function and we will talk about an explicit (explicit is better than implicit!) way of doing this below\n",
    "\n",
    "on a recent project I wanted to read a handful of `csv` files from a single fixed directory (e.g. `/data`) using the `pandas` `pd.read_csv` function. every time I wanted to read these files I wanted to\n",
    "\n",
    "1. read them from the same directory\n",
    "1. lowercase the column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "however, I also wanted to be able to call `pd.read_csv` slightly differently each time\n",
    "\n",
    "1. different files had different sets of columns that were date times\n",
    "1. one file was `\\t` (tab) separated\n",
    "1. one file had `?` characters representing unknowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "for example, the entire operation could be written\n",
    "\n",
    "```python\n",
    "a = pd.read_csv(os.path.join(data_dir, 'a.csv'))\n",
    "a.columns = [col.lower() for col in a.columns]\n",
    "\n",
    "b = pd.read_csv(os.path.join(data_dir, 'b.csv'), sep='\\t')\n",
    "b.columns = [col.lower() for col in b.columns]\n",
    "\n",
    "c = pd.read_csv(os.path.join(data_dir, 'c.csv'), parse_dates=['d0', 'd1'])\n",
    "c.columns = [col.lower() for col in c.columns]\n",
    "\n",
    "d = pd.read_csv(os.path.join(data_dir, 'd.csv'), na_values='?')\n",
    "d.columns = [col.lower() for col in d.columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "we are duplicating a lot of code here, so we could perhaps write the following function to make things a little tighter while still passing through **arbitrary numbers** of args and kwargs:\n",
    "\n",
    "```python\n",
    "data_dir = '/data'\n",
    "def my_read(f_basename, *args, **kwargs):\n",
    "    df = pd.read_csv(os.path.join(data_dir, f_basename), *args, **kwargs)\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    return df\n",
    "\n",
    "a = my_read('a.csv')\n",
    "b = my_read('b.csv', sep='\\t')\n",
    "c = my_read('c.csv', parse_dates=['d0', 'd1'])\n",
    "d = my_read('d.csv', na_values='?')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ if your function arguments already naturally exist in a dictionary (e.g. loading from external configurations)\n",
    "\n",
    "finally, a common practice is to have default parameters for a function saved in a configuration file, to load that into a program, and then use it to call your functions as you get to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "for example, suppose I am training a random forest model and I have the following parameters saved in a `config.py` file\n",
    "\n",
    "```python\n",
    "# file: config.py\n",
    "rf_params = {'n_estimators': 100,\n",
    "             'criterion': 'gini',\n",
    "             'max_depth': 4,\n",
    "             'bootstrap': True,\n",
    "             'oob_score': True,\n",
    "             'n_jobs': -1,\n",
    "             'random_state': 1337, }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "I can load those parameters as a dictionary and pass them all to the `RandomForestClassifier` as\n",
    "\n",
    "```python\n",
    "from config import rf_params\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(**rf_params)\n",
    "```\n",
    "\n",
    "and if I wanted to make a slight change before training I could instead write\n",
    "\n",
    "```python\n",
    "rf_params['criterion'] = 'entropy'\n",
    "rf_params['max_depth'] = None\n",
    "rfc = RandomForestClassifier(**rf_params)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "finally, compare these two equivalent way of passing parameters\n",
    "\n",
    "```python\n",
    "rfc = RandomForestClassifier(**rf_params)\n",
    "\n",
    "# vs.\n",
    "rfc = RandomForestClassifier(n_estimators=rf_params['n_estimators'],\n",
    "                             criterion=rf_params['criterion'],\n",
    "                             max_depth=rf_params['max_depth'],\n",
    "                             bootstrap=rf_params['bootstrap'],\n",
    "                             oob_score=rf_params['oob_score'],\n",
    "                             n_jobs=rf_params['n_jobs'],\n",
    "                             random_state=rf_params['random_state'], )\n",
    "```\n",
    "\n",
    "when you see something like the second, think about cleaning it up with a `**kwargs``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<div align=\"center\">what are your questions so far??</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### mutable default values are very bad\n",
    "\n",
    "defining default values for the arguments in your function is very good!\n",
    "\n",
    "making those default values *mutable* is very bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "in `python`, a *mutable* object is any object which can be changed after it is created. anything which is not mutable is *immutable*. among basic types,\n",
    "\n",
    "| type | mutable |\n",
    "|-|-|\n",
    "| `bool` | |\n",
    "| `int` | |\n",
    "| `float` | |\n",
    "| `str` | |\n",
    "| `tuple` | |\n",
    "| `list` | x |\n",
    "| `set` | x |\n",
    "| `dict` | x |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "you will find that there will be times that you define a function and you want one of the arguments to be a list or a dict. you will want to define the default behavior of that function, and that behavior will often be determined by some default (usually empty) value for that argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "you *may* be temped to write something like\n",
    "\n",
    "```python\n",
    "# DON'T DO THIS\n",
    "def foo(a, b, my_list=[]):\n",
    "    # do stuff...\n",
    "```\n",
    "\n",
    "under the hood this will\n",
    "\n",
    "1. create a function object `foo`\n",
    "1. create a default for the `my_list` argument which is an empty list `[]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "that default value for `my_list` is *persistent* -- it is not re-created each time you invoke the function, but rather re-used.\n",
    "\n",
    "this means that if you do something to that list, the next time you call that function the default value is not `[]` but whatever the last state of that variable was."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the canonical example is a function which will append a value to a list, where the list is optional -- if one isn't provided we will return a list with only the one item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def my_append(my_val, my_list=[]):\n",
    "    my_list.append(my_val)\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "putting aside for a moment that this is a really dumb and contrived way to do this, let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "x = my_append(1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "x = my_append(2, x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = my_append(3, x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "looks good, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "what happens when we try again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "x = my_append(1)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "wat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the default argument we provided (`[]`) was an empty list. when the function was defined, that list was created and stored in memory in `python`. then, every time we made a change to that element it changed *that list*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "```python\n",
    "x = my_append(1)     # the default list is updated to [1] and returned\n",
    "x = my_append(2, x)  # that same list has 2 appended to it, [1, 2]\n",
    "x = my_append(3, x)  # that same list has 2 appended to it, [1, 2, 3]\n",
    "x = my_append(1)     # that default is now [1, 2, 3] and has a 1 appended to it\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "so what's the solution?\n",
    "\n",
    "a very standard pattern in `python` for *mutable* default values is to set a default value of `None` and replace the value when nothing is provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def my_append(my_val, my_list=None):\n",
    "    if my_list is None:\n",
    "        my_list = []\n",
    "    my_list.append(my_val)\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "x = my_append(1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "x = my_append(2, x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = my_append(3, x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "and the moment of truth..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "x = my_append(1)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<div align=\"center\">what are your questions so far??</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### decorators\n",
    "\n",
    "if you've been digging around in `python` for a while, you may have come across funky lines that look like\n",
    "\n",
    "```python\n",
    "@decorator_func\n",
    "def foo(a, b, c):\n",
    "    ...\n",
    "```\n",
    "\n",
    "and wondered what was going on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "statements like `@decorator_func` are called **decorators**, and they are ways to \"decorate\" (aka \"wrap\") a function. it's a syntactical sugar -- an agreed-upon convention for concisely writing a more complicated set of steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### why we would decorate\n",
    "let's take a step back though, and look at examples where we want to \"decorate\" a function, and how we would do it without any special syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*example 1: logging the inputs to a function*\n",
    "\n",
    "suppose I am having a problem with code that I've written and I suspect that the inputs being passed to a function are not what I expect. you've almost certainly made updates to your functions like so:\n",
    "\n",
    "```python\n",
    "def foo(a, b, c):\n",
    "    # do something\n",
    "```\n",
    "\n",
    "becomes\n",
    "\n",
    "```python\n",
    "def foo(a, b, c):\n",
    "    print('a = {}'.format(a))\n",
    "    print('b = {}'.format(b))\n",
    "    print('c = {}'.format(c))\n",
    "    # do something\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "if I wanted to edit *every* function in my script, that might take a long time even though I'm doing basically the same thing for every function! I hate taking a long time to do the same thing, don't you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "we could get around this by defining the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def log_my_parameters(func):\n",
    "    \"\"\"take an input function and create a *new* function\n",
    "    which does the same things as func but prints all input\n",
    "    arguments first\n",
    "    \"\"\"\n",
    "    # define a new, better function that does what we want\n",
    "    def new_better_func(*args, **kwargs):  # <<< wowowowowowowow!\n",
    "        # start by loggin arguments\n",
    "        for (i, arg) in enumerate(args):\n",
    "            print('positional argument {}: {}'.format(i, arg))\n",
    "        for (kw, kwarg) in kwargs.items():\n",
    "            print(\"keyword argument {}: {}\".format(kw, kwarg))\n",
    "        \n",
    "        # then do what the input function does\n",
    "        return func(*args, **kwargs)\n",
    "    \n",
    "    # what we actually return is the new, better function\n",
    "    return new_better_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "we just defined a function which has the ability to convert any arbitrary function into one which prints its arguments. let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sum(a, b, c):\n",
    "    return a + b + c\n",
    "\n",
    "my_sum(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_prod(a, b, c):\n",
    "    return a * b * c\n",
    "\n",
    "my_prod(4, 5, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "and now we create a **wrapped** version of those functions with the same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sum = log_my_parameters(my_sum)\n",
    "\n",
    "my_sum(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prod = log_my_parameters(my_prod)\n",
    "\n",
    "my_prod(4, 5, c=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "above we created one *wrapping* function `log_my_parameters` which can take any function that has arguments (so, any function) and add in `print` of the passed arguments, no matter what that function does. I could wrap functions I didn't create:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_series = log_my_parameters(pd.Series)\n",
    "\n",
    "s = my_series(data=[35, 34, 27, 18, 6], name='age')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*example 2: lowercasing all column names in a dataframe*\n",
    "\n",
    "in the `*args` and `**kwargs` section we created a function which could read `csv` files from a fixed directory and then lowercase all of the columns. suppose we want to continually lowercase columns -- one thing we could do is make a funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_columns_lowercase(df):\n",
    "    df.columns = [col.lower() for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "then, in any function that creates and returns a dataframe, we could add this as a line just before the return\n",
    "\n",
    "```python\n",
    "def my_dataframe_builder():\n",
    "    # do stuff\n",
    "    # do stuff\n",
    "    # do stuff\n",
    "    \n",
    "    make_columns_lowercase(df)\n",
    "    return df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "if we find ourselves doing that many, many times -- or wanting to do it with functions we didn't write, like `pd.read_csv` -- we could convert that single function of a dataframe into a decorator function for decorating other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_columns_lowercase(func):\n",
    "    \"\"\"take a function which returns a dataframe and then make\n",
    "    sure that returned dataframe has its columns lowercased\n",
    "    \"\"\"\n",
    "    def wrapped_func(*args, **kwargs):\n",
    "        df = func(*args, **kwargs)\n",
    "        df.columns = [col.lower() for col in df]\n",
    "        return df\n",
    "    return wrapped_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the function we wrote above was\n",
    "\n",
    "```python\n",
    "data_dir = '/data'\n",
    "def my_read(f_basename, *args, **kwargs):\n",
    "    df = pd.read_csv(os.path.join(data_dir, f_basename), *args, **kwargs)\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    return df\n",
    "```\n",
    "\n",
    "we could have instead **wrapped** a simpler function, this like:\n",
    "\n",
    "```python\n",
    "data_dir = '/data'\n",
    "def my_read(f_basename, *args, **kwargs):\n",
    "    df = pd.read_csv(os.path.join(data_dir, f_basename), *args, **kwargs)\n",
    "    return df\n",
    "\n",
    "my_read = make_columns_lowercase(my_read)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "is this *better*? that's debatable. it's certainly not easier to read. for the extra complexity, we should be getting something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "to re-iterate: the thing we are getting for this complexity is the ability to re-use this functionality (here, logging parameters or lowercasing column names) **across many functions**. if we're only doing it in one or two places, this is needlessly complicated\n",
    "\n",
    "that being said, **if** we are doing the same thing across many functions, this is definitely the best way to do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### the `@decorator` syntax\n",
    "\n",
    "assume we have a decorator function `my_decorator_func`. in the above we kept writing the same basic code:\n",
    "\n",
    "```python\n",
    "def foo(*args, **kwargs):\n",
    "    # do stuff\n",
    "    # do stuff\n",
    "    # do stuff\n",
    "\n",
    "# actually decorate foo\n",
    "foo = my_decorator_func(foo)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "decorating functions like this is common enough that the `python` language supports a special shortcut way of doing this tedious step:\n",
    "\n",
    "```python\n",
    "@my_decorator_func\n",
    "def foo(*args, **kwargs):\n",
    "    # do stuff\n",
    "    # do stuff\n",
    "    # do stuff\n",
    "```\n",
    "\n",
    "the `@my_decorator_func` is a syntactical sugar that tells `python` that the next line will be a function and `python` should apply the decorator function `my_decorator_func` to that function immediately after being defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "so instead of writing\n",
    "\n",
    "```python\n",
    "data_dir = '/data'\n",
    "def my_read(f_basename, *args, **kwargs):\n",
    "    df = pd.read_csv(os.path.join(data_dir, f_basename), *args, **kwargs)\n",
    "    return df\n",
    "\n",
    "my_read = make_columns_lowercase(my_read)\n",
    "```\n",
    "\n",
    "we could write\n",
    "\n",
    "```python\n",
    "data_dir = '/data'\n",
    "\n",
    "@make_columns_lowercase\n",
    "def my_read(f_basename, *args, **kwargs):\n",
    "    df = pd.read_csv(os.path.join(data_dir, f_basename), *args, **kwargs)\n",
    "    return df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "in all of the above we have written the decorator as\n",
    "\n",
    "```python\n",
    "@decorator_function\n",
    "```\n",
    "\n",
    "but you are also allowed to create **parameterized** decorators -- you can write a function which will take some parameters and return a decorator which can then wrap functions in a configurable way. these can be invoked as\n",
    "\n",
    "```python\n",
    "@decorator_function(arg1, arg2, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "for example, if we wanted to modify our column lowercase wrapper function to have exceptions, we could re-write it to take a parameter `except_cols` and build the same decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_columns_lowercase_except(except_cols=None):\n",
    "    \"\"\"build a decorator function which is just like make_columns_lowercase\n",
    "    except it skips over the items in except_cols\n",
    "    \"\"\"\n",
    "    if except_cols is None:  # <<<< wowowowowowowowowowowow\n",
    "        except_cols = []\n",
    "    def the_decorator_func(func):\n",
    "        def wrapped_func(*args, **kwargs):\n",
    "            df = func(*args, **kwargs)\n",
    "            df.columns = [(col if col in except_cols else col.lower())\n",
    "                          for col in df]\n",
    "            return df          # returnception\n",
    "        return wrapped_func    # returnception\n",
    "    return the_decorator_func  # returnception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "@make_columns_lowercase\n",
    "def foo_regular(f, *args, **kwargs):\n",
    "    return pd.read_csv(f, *args, **kwargs)\n",
    "\n",
    "@make_columns_lowercase_except(except_cols=['SePaL_lEnGtH', 'PeTaL_lEnGtH'])\n",
    "def foo_except(f, *args, **kwargs):\n",
    "    return pd.read_csv(f, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_regular('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "            names=['SePaL_lEnGtH', 'sEpAl_WiDtH', 'PeTaL_lEnGtH', 'pEtAl_WiDtH', 'cLaSs']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_except('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "           names=['SePaL_lEnGtH', 'sEpAl_WiDtH', 'PeTaL_lEnGtH', 'pEtAl_WiDtH', 'cLaSs']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### real world use of decorators\n",
    "\n",
    "the further you get into `python` programming, the more decorators you will see. here are a handful of useful and common decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### the `@property` decorator in `class` definitions\n",
    "\n",
    "a `python` `class` can have methods (functions) and properties (static values). you access them as\n",
    "\n",
    "```python\n",
    "# calling a method\n",
    "my_obj.a_method()\n",
    "\n",
    "# accessing a property\n",
    "my_obj.a_property\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "although I wrote above that a property is static, it is possible to have a *dynamically* calculated property if you wrap any method with the `@property` decorator. for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyObject():\n",
    "    def __init__(self, l):\n",
    "        self.list = l\n",
    "    \n",
    "    @property\n",
    "    def length(self):\n",
    "        return len(self.list)\n",
    "\n",
    "o = MyObject([1, 2, 3, 4])\n",
    "o.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.list.append(5)\n",
    "o.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### when making functions in `jupyter` notebooks `interact`ive\n",
    "\n",
    "we will cover this in a section below, but the TL;DR is that any function can get a nifty interactive interface in `python` using the `@interact` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(name=['Zach', 'Caitlin', 'Eamon'])\n",
    "def say_hey(name='Zach'):\n",
    "    print(f'hey {name}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### various functions in the `functools` module, especially `lru_cache`\n",
    "\n",
    "if you learn no other decorator, this is probably the most useful -- the function `functools.lru_cache` is a decorator function for implementing an LRU (`l`east `r`ecently `u`sed) cache -- a way of taking expensive calculations and saving the results in memory so that we don't need to repeat them.\n",
    "\n",
    "this can be extremely useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "imagine you have a function that takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def process_data(x=1, y=2, z=3):\n",
    "    print('processing data for')\n",
    "    print(f'x, y, z = {x}, {y}, {z}')\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    print('processing done')\n",
    "    return x * y * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "every time we run this function we have to wait for the complex processing to happen, even if the exact same results come out on the other side.\n",
    "\n",
    "I hate wasting time doing the same things! I wish we could avoid that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "we can use the `@functools.lru_cache` decorator to save the results of the function for each argument set `x, y, z`. `lru_cache` is a decorator which can take parameters itself, so we call it with `()` rather than just writing the function name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "\n",
    "# maxsize controls how many input params it will cache\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def process_data(x=1, y=2, z=3):\n",
    "    print('processing data for')\n",
    "    print(f'x, y, z = {x}, {y}, {z}')\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    print('processing done')\n",
    "    return x * y * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# the first time with 1, 2, 3\n",
    "process_data(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# the second time with 1, 2, 3\n",
    "process_data(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# the third time with 1, 2, 3\n",
    "process_data(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# the first time with 4, 5, 6\n",
    "process_data(4, 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# the second time with 4, 5, 6\n",
    "process_data(4, 5, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "there are two important thing to know about how `lru_cache` works: it saves the output of the calculation\n",
    "\n",
    "1. in memory\n",
    "1. in a dictionary where the key corresponding to the cached value is the set of parameters\n",
    "\n",
    "this has two implications:\n",
    "\n",
    "1. if your cached result is large, this could cause you to run out of memory. you should consider a file-based or database cache instead\n",
    "1. if your input parameters are not **hashable** (e.g. a `pandas` `DataFrame`), they cannot be the keys in a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "as an example of that second one, while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(1, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will work, the following will throw a `TypeError` because the `Series` object cannot be used as a key in a `dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Series([1, 1, 1], name='x')\n",
    "y = pd.Series([2, 2, 2], name='y')\n",
    "z = pd.Series([3, 3, 3], name='z')\n",
    "\n",
    "process_data(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### in the `flask` web app framework\n",
    "\n",
    "you declare new routes for your web app with the `@app.route()` decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### to declare user defined functions (`udf`s) in `pyspark`\n",
    "\n",
    "in the distributed `pyspark` setting, often you will want to write a function which can be parallelized across many workers. you can do this by prepending your function with `@pyspark.sql.functions.udf(output_type)` -- this will register the following function as a user defined function and make it available in `pyspark` queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<div align=\"center\">what are your questions so far??</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## iteration\n",
    "\n",
    "one of the first-order concepts in `python` is that things which are collections should be *iterable* -- you should be able to move through them in order using a \n",
    "\n",
    "```python\n",
    "for item in collection:\n",
    "    # do a thing...\n",
    "```\n",
    "\n",
    "construct. basically, any time a thing *can* be iteratable, it *should* be iterable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "if you are coming from `R`, or have predominantly executed code in `pandas`, you now that you should try to do *vectorized* things as often as possible. that is definitely still true!!\n",
    "\n",
    "that being said, *outside* of those contexts, you will often be using and creating iterable things, so you should know about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `itertools`\n",
    "\n",
    "iteration is so important that there is a standard library called [`itertools`](https://docs.python.org/3/library/itertools.html) written to support some complex iteration steps. Among many other things, this will allow you to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# iterate through products of different lists\n",
    "# think \"nested for loops\"\n",
    "alist = [0, 1, 2]\n",
    "blist = 'abc'\n",
    "\n",
    "for (a, b) in itertools.product(alist, blist):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# do all combinations with or without replacement\n",
    "for (a0, a1) in itertools.combinations(alist, 2):\n",
    "    print(a0, a1)\n",
    "    \n",
    "print()\n",
    "\n",
    "for (a0, a1) in itertools.combinations_with_replacement(alist, 2):\n",
    "    print(a0, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip together lists with repetition from a shorter list\n",
    "alist = range(10)\n",
    "blist = 'ab'\n",
    "\n",
    "for (a, b) in zip(alist, blist):\n",
    "    print(a, b)\n",
    "    \n",
    "print()\n",
    "\n",
    "for (a, b) in zip(alist, itertools.cycle(blist)):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### list comprehensions\n",
    "\n",
    "you are no doubt familiar with the ability to create lists, sets, and dictionaries using for loops:\n",
    "\n",
    "```python\n",
    "l = []\n",
    "s = set()\n",
    "t = tuple()\n",
    "d = {}\n",
    "for i in range(10):\n",
    "    l.append(i ** 2)\n",
    "    s.add(i ** 2)\n",
    "    t += (i ** 2, )\n",
    "    d[i] = i ** 2\n",
    "```\n",
    "\n",
    "but this actually *not* the preferred way of creating collections from simple iteration. the `pythonic` way of doing that is to use *comprehensions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the following are equivalent:\n",
    "\n",
    "```python\n",
    "l = []\n",
    "s = set()\n",
    "t = tuple()\n",
    "d = {}\n",
    "for i in range(10):\n",
    "    l.append(i ** 2)\n",
    "    s.add(i ** 2)\n",
    "    t += (i ** 2, )\n",
    "    d[i] = i ** 2\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```python\n",
    "l = [i ** 2 for i in range(10)]\n",
    "s = {i ** 2 for i in range(10)}\n",
    "t = tuple(i ** 2 for i in range(10))\n",
    "d = {i: i ** 2 for i in range(10)}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the second form is both faster and more compact -- win win! and if you ask the `python` developers, more readable (though that's definitely debatable)\n",
    "\n",
    "for a general loop structure like\n",
    "\n",
    "```python\n",
    "l = []\n",
    "for elem1 in [some iterable]:\n",
    "    if [conditional check on elem1]:\n",
    "        for elem2 in [some other iterable, maybe depending on elem1]:\n",
    "            if [conditional check on elem2]:\n",
    "                ...\n",
    "                l.append([some expression])\n",
    "```\n",
    "\n",
    "can be replaced with a **comprehension**\n",
    "\n",
    "```python\n",
    "l = [some expression\n",
    "     for elem1 in some iterable\n",
    "     [optional conditional check on elem1]\n",
    "     for elem2 in some other iterable dependent on elem1\n",
    "     [optional condtional check on elem2]\n",
    "     ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "you can think of it as \n",
    "\n",
    "1. moving the final line (which defines what the collection elements are) to the very top\n",
    "1. keeping the `for` loop elements in order\n",
    "1. drop the `:` characters\n",
    "1. move everything to the same indentation level\n",
    "\n",
    "let's verify that the comprehensions we wrote above are equivalent to the nested loop statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(10):\n",
    "    l.append(i ** 2)\n",
    "print(l)\n",
    "\n",
    "print() \n",
    "\n",
    "l = [\n",
    "    i ** 2\n",
    "    for i in range(10)\n",
    "]\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in range(10):\n",
    "    d[i] = i ** 2\n",
    "print(d)\n",
    "\n",
    "print()\n",
    "\n",
    "# note: unlike for loops, comprehension expressions don't\n",
    "# have to be on multiple lines\n",
    "d = {i: i ** 2 for i in range(10)}\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for i in range(5):\n",
    "    if i % 2 == 0:\n",
    "        for j in range(i, 5):\n",
    "            if j % 2 == 0:\n",
    "                d[i, j] = (i ** 2, j ** 3)\n",
    "print(d)\n",
    "\n",
    "print()\n",
    "\n",
    "d = {\n",
    "    (i, j): (i ** 2, j ** 3)\n",
    "    for i in range(5)\n",
    "    if i % 2 == 0\n",
    "    for j in range(i, 5)\n",
    "    if j % 2 == 0\n",
    "}\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "we've actually already used a list comprehension in this lecture -- up above we wrote code to replace all of the columns in a `pandas.DataFrame` with the lowercase version:\n",
    "\n",
    "```python\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "```\n",
    "\n",
    "the equivalent non-comprehension code would have been\n",
    "\n",
    "```python\n",
    "new_cols = []\n",
    "\n",
    "for col in df.columns:\n",
    "    new_cols.append(col.lower())\n",
    "\n",
    "df.columns = new_cols\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### generators\n",
    "\n",
    "you may have been tempted to try this for tuples `(a, b, ...)` as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (i ** 2 for i in range(10))\n",
    "s\n",
    "\n",
    "# note: this is the correct way to do it for a tuple:\n",
    "#s = tuple(i ** 2 for i in range(10))\n",
    "#s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "this is not a set comprehension but isntead a *generator*. you can think of it is a memory-optimized version of the *comprehension* construct above.\n",
    "\n",
    "+ a *comprehension* take some iterables and a rule for composing them into individual values, and then builds all of the items at once and stores them in memory.\n",
    "+ a *generator* acts more like a factory for those items -- it doesn't create them ahead of time, but can if asked\n",
    "\n",
    "You can iterate through either, but if you use a generator you only need to hold one of those things in memory at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ((i ** 2) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep running this cell and see what happens\n",
    "g.send(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "each time we run the `send` method, our generator supplies us with the calculated value (from that recipe) given the next input (from that iterator)\n",
    "\n",
    "in other words, the generator object had an *internal state*, a \"current\" value of those iterated `i` values, and a recipe for converting them into an object which it would then *yield* as we called the `send` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "we can actually see that state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ((i ** 2) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep running the cell and see what happens\n",
    "print(g.send(None))\n",
    "g.gi_frame.f_locals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "of course, you normally wouldn't just create a generator and call `send` on it, you would use the normal iterator `for` loop construct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (i ** 2 for i in range(10))\n",
    "for i2 in g:\n",
    "    print(i2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `yield` in functions\n",
    "\n",
    "finally, you can construct a function which will act like a generator (a way of *generating* items we can iterate over) by using the `yield` keyword in functions. to continue with our example above,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_squares(N):\n",
    "    for i in range(N):\n",
    "        yield i ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "this function will return an iterator where each new iteration will step through the function untill a `yield` is reached or the function exits, and will return whatever is `yield`ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sq in get_squares(4):\n",
    "    print(sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sq in get_squares(10):\n",
    "    print(sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `io` operations and file objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `os`\n",
    "\n",
    "the `os` module has, basically, one goal: handle all the stuff that is different between different operating systems for you. \n",
    "\n",
    "the best example of this is file paths. suppose I want to create a file three directories below the current location: how do I write that path?\n",
    "\n",
    "```sh\n",
    "# in windows:\n",
    "subdir1\\subdir2\\subdir3\\myfile.txt\n",
    "\n",
    "# in linux:\n",
    "subdir1/subdir2/subdir3/myfile.txt\n",
    "```\n",
    "\n",
    "it'd be sad if such a dumb difference broke our script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "in steps the `os` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.join('subdir1', 'subdir2', 'subdir3', 'myfile.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my recommendation: never write a path in `python` again, ever, for any reason. always use `os.path`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the way that `os` joins those directories together is by using the `os.sep` character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "note that if we want to create a path relative to the root directory, then, we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(os.sep, 'tmp', 'myfile.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "another very useful part of the `os` module is the `environ` dictionary object, which is an OS-agnostic way of loading all of the environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: this is a `python` dictionary-like object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PWD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "there are a ton of other goodies in the `os` module, but if you learn nothing else, you should know\n",
    "\n",
    "1. use `os` for building paths -- never write paths as strings!\n",
    "1. you can access environment variables via `os.environ` -- this is one way to parameterize the `python` scripts that you write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `pickle`\n",
    "\n",
    "`python` comes with a built-in **serialization** library called `pickle`.\n",
    "\n",
    "**serialization** is the act of converting some in-memory object into a binary representation (usually then saved to a file) such that you can re-build that in-memory in any other `python` session later. think of it as the default format to \"save\" `python` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the `pickle` module has two main functions:\n",
    "\n",
    "1. `dump`: take a `python` object and \"dump\" it to a file\n",
    "1. `load`: build a new `python` object by loading the contents of a `pickle` file\n",
    "\n",
    "*note: there are also string-based alternatives `dumps` and `loads` where you \"save\" to a string rather than a file, but we won't be using those here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### reading and writing files\n",
    "\n",
    "for many people, the idea of \"opening a file\" is not any different than saying \"here's a file path, go get me all the stuff in it\". for example, at this point, I imagine most of you are familiar with something such as:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/path/to/my/precious/data.csv')\n",
    "```\n",
    "\n",
    "I have a file name, I open it with a function, what else is there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "there are actually many different things you might want to do with a file:\n",
    "\n",
    "1. read the contents into a single `str` because that's what some other package requries\n",
    "1. replace or remove all of the occurrences of a word\n",
    "1. load the first 100 lines only\n",
    "1. search through a file to find out what line a particular string is on\n",
    "1. count all occurrences of a given word\n",
    "1. replace certain characters for easier NLP processing\n",
    "\n",
    "now, you could just load an entire file to a string object or `pandas` data frame, make your changes, and write it out. that's fine until you get to a file that is several GBs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "most of the things I mentioned above that you might want to do involve *iterating* through a file one character or line at a time. this is the fundamental way that `python` handles files.\n",
    "\n",
    "`python` interacts with the file system through a concept called a \"file object,\" which you can basically think of as a cursor pointing to a memory address at a certain point within a file. given where this cursor is currently, the file object could read the next character, the next word, the next line (etc). it could write new contents to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[about 1 million steps under the hood](https://github.com/pandas-dev/pandas/blob/master/pandas/io/common.py#L480-L490), `pd.read_csv` is doing this for you (thanks, `pandas`!), making that `str` path usable.\n",
    "\n",
    "other libraries -- important ones! -- don't take care of you that way.\n",
    "\n",
    "1. `pickle` (builtin serialization package) works on file objects\n",
    "1. `json` and `yaml`, libraries for parsing two of the most common configuration formats, work on file objects\n",
    "1. several parsing libraries (`lxml`, `nltk`) require string inputs or file pointers, so `read_csv` and the like are out\n",
    "1. many non-default deep learning framework file loading operations\n",
    "\n",
    "all I mean to say is: **you will use file objects!**. it's good to know what they are, even at a high level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "let's look at how you use a file object on a low level. if you don't follow right now, don't worry -- you *generally* won't have to do this, but you do very often have to create a file object and pass it to some other function that does, so it's helpful to know more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the main function for interacting with files is the `open` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(open)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### file streams [advanced]\n",
    "\n",
    "the first line of the `help` string on the `open` function says\n",
    "\n",
    "> Open file and return a stream.\n",
    "\n",
    "a *stream* is an abstraction for a collection of data. it is like a list in that it is an ordered sequence of data, but unlike a list in that it is not bounded (it could continue producing items forever) and implies that there are two \"sides\" -- upstream, where new data is generated, and downstream, where that content is sent and consumed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "wherever you find streams transferring data from a producer to a consumer, you might also find a **buffer** -- an in-memory queue of content to consume that is allowed to get arbitrarily large (within memory limits).\n",
    "\n",
    "in `python`, the `open` function returns a **stream** object which can transfer content from a file into the `python` program memory (or vice versa). this object also acts as a **buffer**, storing up content that we want to write to a file or individual lines we want to read from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "we we can get some practice using file objects to learn a bit about streams and buffers (and how IO happens in `linux` in general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "f_out = open('/tmp/testfile.txt', 'w')  # the 'w' says we want to 'w'rite\n",
    "\n",
    "f_out.write('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "less /tmp/testfile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "hm... nothing?\n",
    "\n",
    "we have added the 5 characters `hello` to the *buffer*; we can push them downstream with the `flush` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this saves the writing we've done\n",
    "f_out.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "less /tmp/testfile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f_out.write('world')\n",
    "f_out.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "less /tmp/testfile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "yep -- you have to write *everything*. even spaces, or new line characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f_out.write('\\n')\n",
    "f_out.write('hello\\n')\n",
    "f_out.write('world')\n",
    "f_out.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "less /tmp/testfile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "note: you have to **close** file objects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "so now we have *written* a file using the file object. we use the same `open` function to create a file object to *read* contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in = open('/tmp/testfile.txt', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "you can read the *entire* contents of the file as a single string with `.read`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "f_in.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "we have now consumed the entirely of the *stream* and there is nothing else left to read. if we try to run `.read` *again*, we won't re-read the file -- we will read \"whatever is left\" in the stream, which as of right now is nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "f_in.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "if we want to reference the contents again, we need to either\n",
    "\n",
    "1. have saved it to a variable when we first ran it, or\n",
    "1. close and re-open the file.\n",
    "\n",
    "the ship has sailed on 1, so let's do 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in.close()\n",
    "f_in = open('/tmp/testfile.txt', 'r')\n",
    "s = f_in.read()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f_in.close()\n",
    "\n",
    "# still works after closing the file object\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "above we read *all* of the contents in a file into a single string, but some files (and especially the ones we might care most about!) will be too big to fit in memory\n",
    "\n",
    "we can also *iterate* over the lines in the file, reading in one line at a time. here we are using our **stream** to populate the contents of a **buffer** with one line of characters, then accessing that line of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in = open('/tmp/testfile.txt', 'r')\n",
    "\n",
    "f_in.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f_in.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "finally, we can use the file object as an *iterator* in a `for` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in = open('/tmp/testfile.txt', 'r')\n",
    "\n",
    "for line in f_in:\n",
    "    print(line)\n",
    "\n",
    "f_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "that's enough streaming for now -- let's clean up this testfile and call it a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm /tmp/testfile.txt\n",
    "# mv it day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "so, this may feel a little low-level and annoying, and also overkill for some of our purposes. well, it is. people much smarter and better at programming at `python` did us a solid by writing us a bunch of libraries to handle the reading and writing of data.\n",
    "\n",
    "that being said, *it is super common* that a function wants to take a *file object* and not a name of a file. so you should get used to the idea that you might have to take the extra step of using the `open` function to create a file object from a file name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<div align=\"center\">what are your questions so far??</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "*in the interest of time, I'm going to comment out the `csv` section for lectures. if you're reading at home, this package is super useful, but it's less important than many of the others and I'd rather be sure to get to them than to cover this package*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### `csv` [advanced]\n",
    "\n",
    "before `pandas` dataframes, there were lists of dictionaries:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {'col0': val00, 'col1': val10, 'col2': val20},\n",
    "    {'col0': val01, 'col1': val11, 'col2': val21},\n",
    "    {'col0': val02, 'col1': val12, 'col2': val22},\n",
    "    {'col0': val03, 'col1': val13, 'col2': val23},\n",
    "]\n",
    "```\n",
    "\n",
    "this is one `pythonic` way of representing a csv file: records as dictionaries, and key-value pairs corresponding to header field names and values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "the `csv` module (and specifically the `csv.DictReader` and `csv.DictWriter` objects) allow us to read and write csv files into this data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "x = [\n",
    "    {'a': 1, 'b': 2, 'c': 3},\n",
    "    {'a': 100, 'b': 200, 'c': 300},\n",
    "]\n",
    "\n",
    "# I'll explain what this \"with\" thing is later\n",
    "with open(os.path.join(os.sep, 'tmp', 'myfile.csv'), 'w') as f:\n",
    "    c = csv.DictWriter(f, fieldnames=['a', 'b', 'c'])\n",
    "    c.writeheader()\n",
    "    c.writerows(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "less /tmp/myfile.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "and now we could read it (or any csv) in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# I'll explain what this \"with\" thing is later\n",
    "with open(os.path.join(os.sep, 'tmp', 'myfile.csv'), 'r') as f:\n",
    "    c = csv.DictReader(f)\n",
    "    # note: c is just a special file object; you still need to iterate\n",
    "    # through it all to get all the records!\n",
    "    x = list(c)\n",
    "    \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "an `OrderedDict` is a special class (from the `collections` module) which is simply a dictionary where the order of the keys is remembered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "##### why should you ever do this?\n",
    "\n",
    "generally speaking, you will probably want to read `csv` files in with `numpy`, `scipy`, or `pandas`. however, it is possible you might be in an environment where those are not made available to you.\n",
    "\n",
    "first, ask yourself why you are acting as a data scientist but not allowed to use actual data scientist tools. then, remember that the answer *does* exist in the standard library, and see what you can figure out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## control flow options\n",
    "\n",
    "you are hopefully all very familiar at this point with the `if` / `elif` / `else`, `for`, and `while` control flow keywords. we will talk about a few other options for controlling execution of code in your `python` programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `try`, `except`\n",
    "\n",
    "one of the first major leaps that a beginning programmer makes is recognizing that the code that they wrote won't work for *every* imaginable situation. take, for example, a function that looks to `log`-normalize a feature in your dataset.\n",
    "\n",
    "what happens when your feature contains negative values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the instinct of most beginning programmers is to **proactively protect against** these dangerouse scenarios:\n",
    "\n",
    "```python\n",
    "if (my_feature <= 0).any():\n",
    "    handle_negs(my_feature)\n",
    "else:\n",
    "    log_normalize(my_feature)\n",
    "```\n",
    "\n",
    "programming in this way is called the \"look before you leap\" paradigm -- you check for possible problems and once you're sure none are there, you proceed with your plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "while this will *work*, it's actually not \"the right way (tm).\" there are many reasons, but the most common scenario under which this is not the optimal way forward is the scenario in which the \"bad thing\" (e.g. negative values in your feature) are not normal behavior.\n",
    "\n",
    "almost every time you run your code it would have been fine to just go straight to `log_normalize`, but you had to waste some (even small!) amount of time getting there. that's less efficient and becomes more confusing as more special casses are added. it's not hard to imagine you come across more and more complicated edge cases and the actual \"thing\" you are doing here (`log_normalize`) ends up many, many lines of code deep in your program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "when the thing you are protecting yourself from is an **exception to a rule**, you should instead use the \"easier to ask forgiveness than permission\" paradigm.\n",
    "\n",
    "`try` to do the thing you want to do, and then if there is an `exception` that makes that impossible, \"catch\" that exception and try to do something different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`python` has keywords for this: `try` and `except`\n",
    "\n",
    "```python\n",
    "try:\n",
    "    log_normalize(my_feature)\n",
    "except ValueError:\n",
    "    handle_negs(my_feature)\n",
    "```\n",
    "\n",
    "this will only try to fix negative values if the error (aka `Exception`) that they cause (in this case, a `ValueError`) is raised. adding the `except ValueError` block is referred to as \"handling\" that error, and we can handle many types of errors by adding more `except` statements (just like `elif` statements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `try`, `except`, and custom exceptions\n",
    "\n",
    "one major leap in your programming abilities comes from doing something pretty simple: creating your own exceptions. \n",
    "\n",
    "in this code\n",
    "\n",
    "```python\n",
    "try:\n",
    "    log_normalize(my_feature)\n",
    "except ValueError:\n",
    "    handle_negs(my_feature)\n",
    "```\n",
    "\n",
    "I catch *all* `ValueError` errors, and for each of them I try to handle negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "what happens if the `log_normalize` function failed with a `ValueError` but **not** because of negative numbers? `ValueError` is not *really* specific to the problem I encountered, and other `ValueError`s could easily occur.\n",
    "\n",
    "we can be more specific about what caused our errors by creating our own exceptions. for example, I could have written\n",
    "\n",
    "```python\n",
    "class LogOfNegativeError(Exception):\n",
    "    pass\n",
    "\n",
    "def log_normalize(my_feature):\n",
    "    # blah blah blah\n",
    "    try:\n",
    "        z = math.log(my_feature)\n",
    "    except ValueError:\n",
    "        raise LogOfNegativeError(\n",
    "            \"cannot log norm a feature with a negative value. rescale to positive values\")\n",
    "    # blah blah blah\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "this has two major advantages\n",
    "\n",
    "1. I can tailor it to give much more information to the readers and users of my code\n",
    "    + the error message could be anything -- including steps the user should take to address it\n",
    "1. in code that uses this function, I can be explicit in how I handle it\n",
    "\n",
    "```python\n",
    "try:\n",
    "    log_normalize(my_feature)\n",
    "#except ValueError:\n",
    "except LogOfNegativeError:\n",
    "    handle_negs(my_feature)\n",
    "```\n",
    "\n",
    "now this won't accidentally capture things I *thought* were logs of negative values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<div align=\"center\">what are your questions so far??</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### context managers and the `with` statement\n",
    "\n",
    "in the [reading and writing files section above](#reading-and-writing-files) I said that every time you open a file you must close it.\n",
    "\n",
    "for every\n",
    "\n",
    "```python\n",
    "f = open(fielname, 'r')\n",
    "```\n",
    "\n",
    "there must be a \n",
    "\n",
    "```python\n",
    "f.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "data scientists are only human, and it is extremely possible that in the course of a long and complicated file processing function this simply slips your mind. you're not alone! this could happen to anyone.\n",
    "\n",
    "I've said often that you *must* do this, but not *why*. in the case of streams to the file system -- or other sorts of connections you might make, e.g. to databases -- there is often a limit to the number of simultaneous connections that we are allowed to make. sometimes it's a system resources limitation, sometimes it's a configuration limitation (e.g. only 100 simultaneous users on a database)\n",
    "\n",
    "additionally, you have reserved some amount of your precious `python` process memory for something you don't need any more. with only one open connection, that's not big deal -- but what if it's hundreds? it can happen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "if you forget to close your connections, you're consuming those resources. that's not great!\n",
    "\n",
    "wouldn't it be nice if there were a better way to `open` files? a way that would magically `.close` them as soon as we were done using them?\n",
    "\n",
    "folks, you'll never believe it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*there is!*:\n",
    "\n",
    "\n",
    "```python\n",
    "with open(filename, 'r') as f:\n",
    "    # blah blah\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`with` is a special `python` keyword statement that takes care of the *setup* and *teardown* steps you might need to take for a given object. under the hood, `python` developers have collected all of the things you need to do to *set up*, i.e. correctly open a thing (like a file), and also the things you need to do to *tear down*, i.e. close and clean up a thing (like a file)\n",
    "\n",
    "things that can be passed to the `with` statement are called [**context managers** ](https://docs.python.org/3.7/reference/datamodel.html#context-managers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "when we write\n",
    "\n",
    "```python\n",
    "with [some context manager object] as [alias]:\n",
    "    # do stuff ...\n",
    "```\n",
    "\n",
    "we are\n",
    "\n",
    "1. creating an object and giving it an alias\n",
    "1. \"entering\" a context (defined by that object)\n",
    "1. \"doing stuff\"\n",
    "1. \"exiting\" a context (defined by the object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "let's look at the `open` function as a context manager\n",
    "\n",
    "```python\n",
    "with open('/tmp/testfile.txt', 'w') as f_out:\n",
    "    f_out.write('test test test')\n",
    "```\n",
    "\n",
    "1. we ask `python` to create a file object and give it the alias `f_out`\n",
    "    + this is analogous to `f_out = open('/tmp/testfile.txt', 'w')`\n",
    "1. we \"enter\" a context\n",
    "    + the `open()` file object `f_out` has a method `f_out.__enter__` which is called and \"sets up\" the file object stream\n",
    "1. we do whatever we want (write to the file)\n",
    "1. we \"exit\" the context\n",
    "    + the `f_out.__exit__` method is called and \"tears down\" the file stream (i.e. calls `f_out.flush()` and `f_out.close()` for us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# these functions really do exist\n",
    "f_tmp = open('/tmp/testfile.txt', 'w')\n",
    "\n",
    "f_tmp.__enter__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tmp.__exit__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tmp.__exit__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tmp.closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "recommendation: *never* open a file with\n",
    "\n",
    "```python\n",
    "# bad way -- very bad, no! bad!\n",
    "f = open(filename, 'r')\n",
    "\n",
    "# do stuff\n",
    "\n",
    "f.close()\n",
    "```\n",
    "\n",
    "but *always* use context managers\n",
    "\n",
    "```python\n",
    "# yaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa!\n",
    "with open(filename, 'r') as f:\n",
    "    # do stuff\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the same sort of thing applies to many types of connections you might make in data science\n",
    "\n",
    "+ create a connection to a database\n",
    "    + open the connection on `__enter__`, maybe commits transactions but definitely closes connections on `__exit__`\n",
    "+ create a cursor or a transaction while connected to a database\n",
    "    + build that object on `__enter__`, maybe commit and definitely delete the objecxt on `__exit__`\n",
    "\n",
    "```python\n",
    "with psycopg2.connect(dbname, user, password) as conn:  # __enter__ creates a connection\n",
    "    with conn.cursor() as cur:  # __enter__ creates a cursor and starts a transaction\n",
    "        cur.execute(my_special_query)\n",
    "        # cursor __exit__ commits transaction and destroys cursor\n",
    "    # connection __exit__ closes the connection\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ a `tensorflow` session (prior to `tf 2.0`)\n",
    "    + the `__enter__` prepares a graph for execution and the `__exit__` cleans up the `tensorflow` graph\n",
    "\n",
    "```python\n",
    "with tf.Session() as sess:\n",
    "    sess.run([my_tensor_op])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "if you can use a context manager, **always** use a context manager\n",
    "\n",
    "this way you will *never forget* and if the context object (here, a file object) ever gets more complex or requires more clean up *you don't have to care*, and not having to care is the very heart of good programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<div align=\"center\">what are your questions so far??</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## string formatting\n",
    "\n",
    "you should read [this entire format string syntax page](https://docs.python.org/3.7/library/string.html#formatstrings).\n",
    "\n",
    "the basic gist of it, though, is that there is that every string object `s` in python has a member function\n",
    "\n",
    "```python\n",
    "s.format(...)\n",
    "```\n",
    "\n",
    "and this can be used to replace elements within the string that are coded within `{}` characters. There is a large and highly flexible mini-language for doing this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "in particular, we can\n",
    "\n",
    "+ pass an arbitrary number of *positional* arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "myname = 'zach'\n",
    "'hello {}, how are you today'.format(myname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "yourname = 'caitlin'\n",
    "mymood = 'great'\n",
    "\"hey {}, I'm {}\".format(yourname, mymood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ parameterize the string and provide values as named arguments (for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# look -- keyword explosion in the wild!!\n",
    "'{name} is feeling {mood} today'.format(name='zach', mood='groovy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# look -- keyword argument explosion in the wild!!\n",
    "me = {'name': 'zach', 'mood': 'groovy', }\n",
    "'{name} is feeling {mood} today'.format(**me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ control the precision of floating point numbers we print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "'here are only the first three decimal places: {:.3}'.format(0.123456789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ left, right, or center align\n",
    "+ set a fixed size of the output\n",
    "+ set a fill character (to fill the output where the thing-to-be-format-ted doesn't fill it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "s = 'left aligned with \"x\"s '\n",
    "'{:x<60}'.format(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "s = ' center aligned with \"-\"s '\n",
    "'{:-^60}'.format(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "s = ' right aligned with \"*\"s'\n",
    "'{:*>60}'.format(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ format datetime using the same basic commands we use in the `date` function in `bash`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "d = datetime.now()\n",
    "'right now it is {:%Y-%m-%d %H:%M:%S}'.format(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "'which is the same as {d:%F %T}, aka {d:%b %d, %Y at %T}'.format(d=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `f`-strings\n",
    "\n",
    "starting in `python` version 3.6, there is also a second option for formatting strings -- `f`-strings. these basically skip the entire `.format(arg=val)` portion by looking in the local scope for variables with those names. for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "your_name = 'Caitlin'\n",
    "my_name = 'Zach'\n",
    "\n",
    "# this won't work if you're in python 3.5 or below\n",
    "f'Hello {your_name}, my name is {my_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<div align=\"center\">mini exercise: write \"hello world\" to file</div>**\n",
    "\n",
    "1. create a function `hello_world(name)` that\n",
    "    1. takes a person's name as its first variable\n",
    "    2. uses string formatting to creates a greeting message that uses `name` (e.g. \"hello [NAME HERE], how are you today?\")\n",
    "    3. open a file `/tmp/test.txt` using the `with` context manager construct\n",
    "    4. write that string to file\n",
    "    5. in bash, print the results of that code to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(os.sep, 'tmp', 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def hello_world(name):\n",
    "    s = 'hello {}, how are you today?'.format(name)\n",
    "    filename = os.path.join(os.sep, 'tmp', 'test.txt')\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(s)\n",
    "    \n",
    "hello_world('caitlin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat /tmp/test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# to clean up\n",
    "rm /tmp/test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `pandas`\n",
    "\n",
    "`pandas` is *the* data science data structure package. in the latter parts of this course we will be using `pandas` and `scikit-learn` to do some of our analyses, so I'll push the learning of `pandas` off until then. Just know that you should learn `pandas`.\n",
    "\n",
    "In many ways, `pandas` is a second programming language. because it sits part-way between python (where there is one and only one way to do things, iteration is a first-order principle) and `R` (where everything is vectorized there is a paradigm shift relative to the `R` community: whereas the `R` community is focused on making the language easy and intuitive for the user, the `pandas` community defaults more toward the development community. this will make the learning curve particularly steep for most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "    names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('class').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## plotting and exploratory visualization\n",
    "\n",
    "okay, okay, I hear you: \"but all I want to do is plot\"\n",
    "\n",
    "one common knock against `python` is that it makes plotting so much harder than `R`, and that is absolutely a valid complaint. That being said, I don't think it is *quite* as bad as people like to make it out to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `matplotlib`\n",
    "\n",
    "this is the primary plotting workhorse in the `python` world, and also the source of much of the angst. the name comes from the fact that this package was actually built as an attempted replacement plotting package for *matlab* transfers.\n",
    "\n",
    "rather than dive into a whole tutorial about `matplotlib`, let me just offer a few pieces of advice:\n",
    "\n",
    "1. begin any notebook in which you plan to plot with `%matplotlib inline` or `%matplotlib notebook`\n",
    "2. favor the object oriented method (*e.g.* `f, ax = matplotlib.pyplot.subplots(); ax.plot(x, y)`) over the \"interactive\" `pyplot` method (*e.g.* `matplotlib.pyplot.plot(x, y)`).\n",
    "3. you're probably using `pandas`, so lean on the `pandas` plotting builtins\n",
    "4. import `seaborn` first; it will configure almost all of the defaults for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [random.gauss(0, 1) for i in range(1000)]\n",
    "y = [random.gauss(0, 1) for i in range(1000)]\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(x, y, linestyle='', marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `matplotlib` with `pandas`\n",
    "\n",
    "the good folks behind `pandas` decided to build support for `matplotlib` plotting directly into their dataframe object interface, so often times you are best off calling a dataframe's `plot` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x': x, 'y': y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.plot.scatter('x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `seaborn`\n",
    "\n",
    "think of `seaborn` as a sort of conceptual gradient boost to `matplotlib` -- it was created to handle some of the rough edges for the statistical community, and makes first-class some familiar `R` plotting concepts such as\n",
    "\n",
    "1. easy distribution and kde plots\n",
    "2. panel plotting\n",
    "3. plot types\n",
    "    1. violin plots, box and whisker plots, swarmplots\n",
    "4. plotting features\n",
    "    1. jitter, nicer default color schemes\n",
    "5. several statistically familiar datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "if you do nothing else to make your plots better, I recommend starting every notebook with\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('x', 'y', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('x', 'y', data=df, kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "sns.pairplot(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `plotly`\n",
    "\n",
    "finally, I strongly urge you to check out `plotly`. it has come a long way since the early days (in which it was a fundamental requirement that you post your plots to a public website -- a total non-starter for work with sensitive or proprietary information, for example). it is based on a language-independent graphical object model, and as a result not only is the process of *creating* graphs nearly identical from `R` to `python` to `matlab` to `julia` to (you get it), but converting from one language to another is actually built in to the package itself.\n",
    "\n",
    "plus, it's a `d3` based `javascript`-first package, so it often has some of the cool web bells and whistles before most of the others do (really, before any of them do in `python`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Scatter(x=df.x,\n",
    "                   y=df.y,\n",
    "                   mode='markers')]\n",
    "\n",
    "fig = go.Figure(data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "in much the same way as `seaborn` provides a thin wrapper around `matplotlib` for making the most common but complicated statistical plot types, `plotly.express` wraps base `plotly` to give a second useful interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df, x=\"x\", y=\"y\", marginal_x=\"histogram\", marginal_y=\"histogram\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `ipywidgets` and `interact`\n",
    "\n",
    "in the `decorator`s section above I mentioned the `interact` function, a useful way of creating interactive widgets for you (or others) to parameterize and re-run certain functions.\n",
    "\n",
    "`interact` is a part of the [`ipywidgets`](https://ipywidgets.readthedocs.io/en/latest/index.html) package which can allow you to build fairly sophisticated user interfaces with a small amount of effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "there are [a ton of supported widgets](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html) -- basically, any basic type of data you might use as a parameter is usable as a widget parameter.\n",
    "\n",
    "`ipywidgets` will do it's best to guess what sort of widget makes sense for your function, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "# guesses str --> text box\n",
    "# guesses int --> int slider\n",
    "@interact()\n",
    "def say_hey(name='Zach', num=13):\n",
    "    print(f'hey {name}!')\n",
    "    print(f'my favorite number is {num}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "it is also possible to be explicit about the type of widget you want to use while `@interact`int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets.widgets import Checkbox, Dropdown, IntSlider, FloatSlider, RadioButtons, ToggleButton\n",
    "@interact(i=IntSlider(0, -10, 10),\n",
    "          f=FloatSlider(value=0, min=-10, max=10, step=0.25),\n",
    "          name=Dropdown(value=\"Zach\", options=['Zach', 'Caitlin', \"Eamon\"]),\n",
    "          m=RadioButtons(value='happy', options=['happy', 'sad', 'anxious']),\n",
    "          b=Checkbox(value=False, description='my boolean'),\n",
    "          t_info=ToggleButton(value=True, description='info', button_style='info'),\n",
    "          t_danger=ToggleButton(value=True, description='danger', button_style='danger'), )\n",
    "def foo(i=0, f=0.0, name='Zach', m='happy', b=True, t_info=True, t_danger=False):\n",
    "    print(f'my integer is {i}')\n",
    "    print(f'my float is {f}')\n",
    "    print(f'my name is {name}')\n",
    "    print(f'my mood is {m}')\n",
    "    print(f'my boolean is {b}')\n",
    "    print(f'my info bool is {t_info}')\n",
    "    print(f'my danger bool is {t_danger}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `tqdm`\n",
    "\n",
    "finally, we have a package that is just for aesthetic preferences, but makes a huge difference for you as a user of `python`. when you have a long-running script where you iterate over a large number of steps, it's nice to be able to look at a simple summary of how far you've gone and how long you have yet to go\n",
    "\n",
    "the `tqdm` package is a progress bar package that has the ability to print out raw text (in a console) or javascript-based (in a `notebook`) progress bar for any iterable in `python`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the usage is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "for i in trange(20):\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## that `__main__` thing\n",
    "\n",
    "at the very beginning of this lecture there was a section on how you should write scripts that are either\n",
    "\n",
    "1. a module -- something you `import` that doesn't do anything without being told\n",
    "1. a script -- a file you run from the `bash` command line as `python [filename].py`, that does something\n",
    "\n",
    "in reality, it *is* possible -- even common -- to *kind of* do both. ***kind of***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "I wrote a \"better idea\" version of a module file, and it ended with this block:\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```\n",
    "\n",
    "this complicated block appears [all over `python` code](https://github.com/search?l=Python&q=__name__+__main__&type=Code) (27M+ examples as of Oct 2019), and it is basically a hack to figure out which of the two \"modes\" (importing a module or running a script) we are using.\n",
    "\n",
    "so how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "as I said above, there are two types of `python` files: modules that provide functions for doing things, and scripts that acutally do things. \n",
    "\n",
    "modules all have a \"name\" member variable which is accessible via\n",
    "\n",
    "```python\n",
    "mymodule.__name__\n",
    "```\n",
    "\n",
    "(pronounced \"mymodule dunder name\").\n",
    "\n",
    "for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging.config\n",
    "logging.config.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the `__name__` variable value can be hard-coded to be something special within the source code of the module, but by default it is the same as the module name. so, if you wrote a `python` file `thing.py`, without making any change at all you would find that the code\n",
    "\n",
    "```python\n",
    "import thing\n",
    "thing.__name__\n",
    "```\n",
    "\n",
    "would print the string \n",
    "\n",
    "```\n",
    "'thing'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "what's going on here is roughly the following:\n",
    "\n",
    "1. the `python` interpreter sees that you want to `import thing`\n",
    "2. it creates a \"namespace\" for `thing`\n",
    "    1. a \"namespace\" is a segmented place where the contents (e.g. functions) of the `thing` can be put\n",
    "        1. helps avoid naming conflicts\n",
    "        2. is basically a big dictionary with \"names\" and the compiled objects they point to (like functions, values)\n",
    "    2. a special variable `__name__` is created inside the `thing` module with a value `\"thing\"`\n",
    "    3. all of the functions and values in `thing.py` are then executed and loaded into the `thing` namespace\n",
    "    4. within the scope of `thing.py`, it is known that the \"name\" of their namespace is `thing`\n",
    "3. all of the items in the `thing` module are then made available as `thing.SOME_ITEM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "so when you execute the command `import os`, `python`\n",
    "\n",
    "1. creates a \"namespace\" called `os` where it can save the things defined in the `os` file\n",
    "1. finds a file `os.py` somewhere on its path\n",
    "1. reads the contents of `os.py` and builds the things (functions, classes, constants) defined therein\n",
    "\n",
    "if there is no variable inside `os` called `__name__`, `python` creates one with a value `os.__name__ = 'os'`\n",
    "\n",
    "after this, you have access to many new functions and properties under `os.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "this is what happens when you `import` some external module like `os`, but a similar sort of thing happens when you start `python`. in this case `python` creates a default namespace called the `__main__` namespace, where a handfull of builtin functions (e.g. `int`, `dict`) are defined, and available *without* any prefix.\n",
    "\n",
    "this includes a special, initial `__name__` variable that doesn't have any namespace prefix -- it's the `__name__` of the \"script environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### why does this matter, though?\n",
    "\n",
    "so assume we've written a file `thing.py`\n",
    "\n",
    "+ if we run `import thing`, `python` will create a namespace `thing` and the value of `__name__` inside that namespace will be `thing.__name__ == 'thing'`.\n",
    "    + anything in `thing.py` which references `__name__` will resolve to `'thing'`\n",
    "+ if we run the commands in `thing.py` in the base script environment (e.g. when we write `python thing.py` from the `bash` command line), the code in `thing.py` will be executed in the main environemnt where `__name__` will be set to `__main__`\n",
    "    + anything in `thing.py` which references `__name__` will resolve to `'__main__'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "so what does it mean to have a block\n",
    "\n",
    "```python\n",
    "# a bunch of code\n",
    "# ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    do_a_thing()\n",
    "```\n",
    "\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "the answer:\n",
    "\n",
    "+ when you `import thing`, `__name__ == '__main__'` will resolve to `False` because `__name__ == 'thing'`\n",
    "+ when you run `python thing.py` from the command line, `__name__ == '__main__'` will resolve to `True`\n",
    "\n",
    "this means that the code that follows `if __name__ == '__main__'` will **only** be executed if you're running from the command line, and will **never** be run if you `import thing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**ultimately**, if you write your code to have this \"dunder main\" block at the end, it will serve as a logical switch between \"code is being imported\" and \"code is being run from the command line\".\n",
    "\n",
    "if you furthermore clean up the code above the `if __name__ == \"__main__\"` line to be only function definitions -- no running code or changing state -- your `python` file will be entirely *explicit*: users can directly invoke it from the command line or after `import`ing it, but it will never be invoked accidentally on `import`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**<em><div align=\"center\">YESSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS</div></em>**\n",
    "<div align=\"center\"><img src=\"http://ih0.redbubble.net/image.13413141.8561/flat,550x550,075,f.u3.jpg\"></div>\n",
    "\n",
    "# END OF LECTURE\n",
    "\n",
    "next lecture: [environment management pt. 1: anaconda](006_environments_1_anaconda.ipynb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "322.5px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
